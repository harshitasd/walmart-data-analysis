{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOs2zOgolqLinjrl67LEf4b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitasd/walmart-data-analysis/blob/main/walmart_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-ZAOUumNH6p",
        "outputId": "04081c89-4297-4fcc-f513-1124c257bfb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CPU times: user 1.26 s, sys: 229 ms, total: 1.49 s\n",
            "Wall time: 1.99 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Installing select libraries:-\n",
        "from gc import collect; # garbage collection to free up memory\n",
        "from warnings import filterwarnings; # handle warning messages\n",
        "\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np # linear algebra\n",
        "\n",
        "import matplotlib.pyplot as plt # data visualization\n",
        "import seaborn as sns # statistical data visualization\n",
        "\n",
        "# Set the plot style to 'fivethirtyeight'\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "\n",
        "from datetime import datetime  # Importing the datetime class from the datetime module\n",
        "\n",
        "from scipy import stats # statistical functions\n",
        "\n",
        "filterwarnings('ignore'); # Ignore warning messages\n",
        "from IPython.display import display_html, clear_output; # displaying HTML content\n",
        "\n",
        "\n",
        "clear_output();\n",
        "print();\n",
        "collect();"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Error Handling When Loading Dataset with Pandas read_csv\n",
        "\n",
        "try:\n",
        "    # Attempt to read the dataset\n",
        "    df = pd.read_csv('/kaggle/input/walmart-sales/Walmart_sales.csv')\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    # Handle FileNotFoundError if the file does not exist\n",
        "    print(\"Error: File not found. Please check the file path.\")\n",
        "\n",
        "except Exception as e:\n",
        "    # Handle other exceptions\n",
        "    print(\"An error occurred while loading the dataset:\", e)\n",
        "\n",
        "print();\n",
        "collect();"
      ],
      "metadata": {
        "id": "RoTxPtKpNV1R"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the columns name\n",
        "df.columns"
      ],
      "metadata": {
        "id": "rDeNlZTmNr3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Rename columns to lowercase\n",
        "df.columns = df.columns.str.lower()\n",
        "\n",
        "# Verify the new column names\n",
        "print(\"\\nNew column names:\")\n",
        "print(df.columns)\n",
        "\n",
        "print();\n",
        "collect();"
      ],
      "metadata": {
        "id": "c8f56WgGNyEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the null values in the dataset\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "-KDnx9VtN4Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#information about the dataset\n",
        "df.info()"
      ],
      "metadata": {
        "id": "L6hI5BoMN9co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attempt to convert 'date' column to datetime format\n",
        "try:\n",
        "    df['date'] = pd.to_datetime(df['date'], format='mixed')\n",
        "    print(\"All values in 'date' column are valid dates.\")\n",
        "except ValueError as e:\n",
        "    print(\"Error:\", e)\n",
        "    print(\"There are non-date values present in the 'date' column.\")"
      ],
      "metadata": {
        "id": "0B86PZ7MODqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the duplicate values in the data\n",
        "duplicate_values=df.duplicated().sum()\n",
        "print(f'The data contains {duplicate_values} duplicate values')"
      ],
      "metadata": {
        "id": "O1KqFfO6OJdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the data shape\n",
        "print(f'The dataset contains {df.shape[0]} rows and {df.shape[1]} columns')"
      ],
      "metadata": {
        "id": "LxKcw8fdOTQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistics about the data set\n",
        "df.describe().style.background_gradient(cmap='bone_r')"
      ],
      "metadata": {
        "id": "aQH_hXQBOZx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to map dates to seasons\n",
        "def date_to_season(date):\n",
        "    # Extract month from date string and convert it to integer\n",
        "    month = datetime.strptime(date, \"%Y-%m-%d\").month\n",
        "\n",
        "    # Map months to seasons\n",
        "    if month in [3, 4, 5]:\n",
        "        return \"Spring\"\n",
        "    elif month in [6, 7, 8]:\n",
        "        return \"Summer\"\n",
        "    elif month in [9, 10, 11]:\n",
        "        return \"Autumn\"\n",
        "    else:\n",
        "        return \"Winter\"\n",
        "\n",
        "# Apply date_to_season function to create a new column\n",
        "df[\"season\"] = df[\"date\"].apply(lambda x: date_to_season(x.strftime(\"%Y-%m-%d\")))"
      ],
      "metadata": {
        "id": "w7_Zq1ruOenJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract year from the 'date' column\n",
        "df['year'] = df['date'].dt.year\n",
        "\n",
        "# Extract month from the 'date' column\n",
        "df['month'] = df['date'].dt.month\n",
        "\n",
        "# Extract month name from the 'date' column\n",
        "df['month_name'] = df['date'].dt.month_name()\n",
        "\n",
        "# Extract day from the 'date' column\n",
        "df['day'] = df['date'].dt.day\n",
        "\n",
        "# Extract day of the week (0 = Monday, 1 = Tuesday, ..., 6 = Sunday) from the 'date' column\n",
        "df['day_of_week'] = df['date'].dt.dayofweek\n",
        "\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "66EY7A_6OllV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of features\n",
        "features = ['weekly_sales', 'temperature', 'fuel_price', 'cpi', 'unemployment']\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(18, 20))\n",
        "\n",
        "# Loop through each column in your dataset\n",
        "for i, col in enumerate(features):\n",
        "    # Create subplots\n",
        "    plt.subplot(3, 3, i+1)\n",
        "\n",
        "    # Plot histogram for the current column\n",
        "    sns.histplot(data=df, x=col, kde=True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LyoZYvnmOtfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = df[['weekly_sales', 'temperature', 'fuel_price', 'cpi', 'unemployment']].corr()\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lOiuF3dLO2L9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.pivot_table(data = df,\n",
        "              index = 'year',\n",
        "              columns = 'season',\n",
        "              values = 'weekly_sales',\n",
        "              aggfunc = 'sum')"
      ],
      "metadata": {
        "id": "5Fw3lcnkO5lJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary to store season-wise weekly sales for each year\n",
        "seasonwise_weekly_sales = {}\n",
        "\n",
        "# Iterate over unique seasons\n",
        "for season in df['season'].unique():\n",
        "    # Group by year and sum the weekly sales for the current season\n",
        "    season_sales = df[df['season'] == season].groupby('year')['weekly_sales'].sum()\n",
        "    # Store the season-wise weekly sales in the dictionary\n",
        "    seasonwise_weekly_sales[season] = season_sales\n",
        "\n",
        "# Create an empty list to store data\n",
        "plot_data = []\n",
        "\n",
        "# Populate the list with data\n",
        "for season, sales in seasonwise_weekly_sales.items():\n",
        "    for year, weekly_sales in sales.items():\n",
        "        plot_data.append({'Year': year, 'Season': season, 'Weekly Sales': weekly_sales})\n",
        "\n",
        "# Convert the list to a DataFrame\n",
        "plot_data = pd.DataFrame(plot_data)\n",
        "\n",
        "# Create the figure and axes\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Plot the stacked bar plot using seaborn\n",
        "sns.barplot(data=plot_data, x='Year', y='Weekly Sales', hue='Season', ax=ax, ci=None)\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Year')\n",
        "ax.set_ylabel('Total Weekly Sales')\n",
        "ax.set_title('Yearly Season-wise Total Weekly Sales')\n",
        "# Adjust legend position to prevent it from going outside the plot\n",
        "ax.legend(title='Season', loc='upper left', bbox_to_anchor=(1, 1))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LgC1e3KOPEl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by year and holiday_flag to get counts\n",
        "holiday_counts = df.groupby(['year', 'holiday_flag']).size().unstack(fill_value=0).reset_index()\n",
        "\n",
        "# Melt DataFrame to long format\n",
        "holiday_counts_melted = pd.melt(holiday_counts, id_vars='year', var_name='Holiday Flag', value_name='Count')\n",
        "\n",
        "# Plot using Seaborn\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Bar plot\n",
        "sns.barplot(data=holiday_counts_melted, x='year', y='Count', hue='Holiday Flag', ax=ax[0])\n",
        "ax[0].set_title('Holiday Distribution Over the Years')\n",
        "ax[0].set_xlabel('Year')\n",
        "ax[0].set_ylabel('Count')\n",
        "\n",
        "# Get legend handles\n",
        "handles, _ = ax[0].get_legend_handles_labels()\n",
        "\n",
        "ax[0].legend(handles=handles, labels=['Not Holiday', 'Holiday'], title='Holiday Flag', loc='upper left', bbox_to_anchor=(1, 1))\n",
        "\n",
        "ax[1].pie(df['holiday_flag'].value_counts().values, labels=['Not Holiday', 'Holiday'], autopct='%1.2f%%')\n",
        "ax[1].set_title('Overall Holiday Distribution')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qgmh_MBpPMiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the count of each year\n",
        "year_counts = df['year'].value_counts()\n",
        "\n",
        "# Plotting\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Countplot for the distribution of years\n",
        "sns.countplot(data=df, x='year', ax=ax[0])\n",
        "ax[0].set_xlabel('Year')\n",
        "ax[0].set_ylabel('Count')\n",
        "\n",
        "# Pie chart for the distribution of years\n",
        "ax[1].pie(year_counts.values, labels=year_counts.index, autopct='%1.2f%%')\n",
        "\n",
        "# Set a single title for the entire figure\n",
        "plt.suptitle('Distribution of Years', fontsize=16, y=1.05)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oPukdT3ePQlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wmh1-5RkPbJT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}